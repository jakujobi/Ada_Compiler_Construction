# jakadac Module Documentation

This folder contains the core compiler components for the Ada compiler project. Each module implements a specific compilation phase or utility.

## Modules

- **Token.py**
  Defines the `Token` class representing lexical tokens, including type, lexeme, position, and literal values.

- **Definitions.py**
  Contains the `Definitions` class with token type enumerations, reserved words, and regular-expression patterns used by the lexical analyzer.

- **Logger.py**
  Provides a centralized `Logger` class and instance for uniform logging across all modules.

- **FileHandler.py**
  Utility for reading and writing files (source code input and output generation).

- **LexicalAnalyzer.py**
  Implements the `LexicalAnalyzer` that scans Ada source code and produces a list of `Token` objects.

- **RDParser.py**
  Implements a recursive-descent parser (`RDParser`) that consumes tokens, performs syntax checks, reports syntax errors, and optionally builds a parse tree.

- **ParseTree.py**
  Defines `ParseTreeNode` and related classes for representing and printing the parse tree generated by `RDParser`.

- **SymTable.py**
  Implements the `SymbolTable` and `Symbol` classes for managing declarations, scoping, duplicate checks, and symbol lookups. Supports nested scopes.

- **NewSemanticAnalyzer.py**
  Implements the `NewSemanticAnalyzer` that traverses the parse tree to perform semantic actions, populate the symbol table, enforce declaration rules, compute offsets, and dump scope contents.

- **Driver.py**
  Provides the `BaseDriver` class to orchestrate compilation phases (lexical, syntax, semantic), handle command-line arguments, manage logging, and print summaries.

- **TypeUtils.py**
  Helper functions (`TypeUtils`) for converting between token types and `VarType` enums, and for computing type sizes.

- **RDParserExtended.py**
  A variant of the parser with additional grammar rules and recovery strategies (extension of `RDParser`).

- **TACGenerator.py**
  Implements the `ThreeAddressCodeGenerator` for producing three-address code IR with depth-based addressing and constant substitution.

## Usage

1. **Lexical Analysis**
   ```python
   from jakadac.modules.LexicalAnalyzer import LexicalAnalyzer
   lexer = LexicalAnalyzer()
   tokens = lexer.analyze(source_code)
   ```

2. **Syntax Analysis**
   ```python
   from jakadac.modules.RDParser import RDParser
   parser = RDParser(tokens, lexer.defs, build_parse_tree=True)
   success = parser.parse()
   tree = parser.parse_tree_root
   ```

3. **Symbol Table & Semantic Analysis**
   ```python
   from jakadac.modules.SymTable import SymbolTable
   from jakadac.modules.NewSemanticAnalyzer import NewSemanticAnalyzer

   symtab = SymbolTable()
   analyzer = NewSemanticAnalyzer(symtab, tree, lexer.defs)
   no_errors = analyzer.analyze()
   ```

4. **Driver Integration**
   Use `BaseDriver` in `Driver.py` to tie together all phases:
   ```python
   from jakadac.modules.Driver import BaseDriver
   class MyDriver(BaseDriver):
       # implement custom behavior or reuse BaseDriver.run_lexical/run_syntax/run_semantic
   ```

5. **Three-Address Code Generation**
   ```python
   from jakadac.modules.TACGenerator import ThreeAddressCodeGenerator
   tacgen = ThreeAddressCodeGenerator(symbol_table, parse_tree_root)
   tac_program = tacgen.generate()
   ```

Refer to individual module docstrings for detailed API documentation and examples. 