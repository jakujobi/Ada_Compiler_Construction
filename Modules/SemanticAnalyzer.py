#!/usr/bin/env python3
# SemanticAnalyzer.py
# Author: John Akujobi
# GitHub: https://github.com/jakujobi/Ada_Compiler_Construction
# Date: 2025-03-31
# Version: 1.0
"""
Semantic Analyzer for Ada Compiler

This module performs semantic analysis on the parse tree generated by the parser.
It performs the following semantic actions:
- Insert constants, variables, and procedures into the symbol table
- Set the value or type for constants and variables, including size and current offset
- Track the size of local variables and parameters for procedures
- Reject multiple declarations of the same name at the same depth
- Print the contents of the symbol table upon exiting each procedure and at the end

The semantic analyzer walks the parse tree and performs the appropriate semantic actions
based on the grammar productions. It reports semantic errors and continues analysis
when possible, or stops at the first error if configured to do so.
"""

import os
import sys
from typing import List, Dict, Optional, Any, Tuple
from prettytable import PrettyTable

# Add the parent directory to the path so we can import modules
repo_home_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.append(repo_home_path)

from Modules.Token import Token
from Modules.Definitions import Definitions
from Modules.RDParser import ParseTreeNode
from Modules.AdaSymbolTable import AdaSymbolTable, VarType, EntryType, ParameterMode, Parameter, TableEntry
from Modules.Logger import Logger


class SemanticAnalyzer:
    """
    Semantic analyzer for Ada compiler.
    
    This class walks the parse tree and performs semantic actions according to
    the Ada grammar, including symbol table management, type checking, and 
    tracking of variable offsets.
    """
    
    def __init__(self, symbol_table: AdaSymbolTable, stop_on_error: bool = False, logger: Logger = None):
        """
        Initialize the semantic analyzer.
        
        Args:
            symbol_table: The symbol table to use for semantic analysis
            stop_on_error: Whether to stop at the first error or continue
            logger: An optional logger instance for logging errors and information
        """
        self.symbol_table = symbol_table
        self.stop_on_error = stop_on_error
        self.logger = logger if logger else Logger()
        self.errors = []
        self.current_depth = 0
        self.current_offset = 0
        
        # For managing variable memory allocation
        self.depth_offsets = {0: 0}  # Track offset for each depth level
        
        # Define sizes for each variable type
        self.type_sizes = {
            VarType.INT: 2,      # Integers have size 2
            VarType.CHAR: 1,     # Characters have size 1
            VarType.FLOAT: 4,    # Floats have size 4
            VarType.REAL: 4      # Alias for FLOAT
        }
        
        # Define mapping from token types to variable types
        self.token_to_var_type = {
            "INTEGERT": VarType.INT,
            "REALT": VarType.FLOAT,
            "CHART": VarType.CHAR,
            "FLOAT": VarType.FLOAT
        }
    
    def analyze_parse_tree(self, parse_tree_root: ParseTreeNode) -> bool:
        """
        Analyze the parse tree and perform semantic actions.
        
        Args:
            parse_tree_root: The root of the parse tree from the parser
            
        Returns:
            True if analysis was successful, False otherwise
        """
        if not parse_tree_root:
            self.report_error("No parse tree to analyze", line=0, column=0)
            return False
        else:
            self.logger.info("There is a parse tree to analyze")
            
        # Start analysis at the program level
        result = self.analyze_prog(parse_tree_root)
        
        # At the end of analysis, print all entries remaining at depth 0.
        print("\nRemaining global entries at depth 0:")
        self.print_symbol_table(0)
        
        # Return success only if no errors were found
        return result and len(self.errors) == 0
    
    def analyze_prog(self, node: ParseTreeNode) -> bool:
        """
        Analyze a Prog node in the parse tree.
        
        Grammar rule: Prog -> procedure idt Args is DeclarativePart Procedures begin SeqOfStatements end idt;
        
        Actions:
        1. Enter a new scope (increment depth)
        2. Insert procedure name into symbol table at parent depth
        3. Process arguments (if any)
        4. Process declarative part (variable/constant declarations)
        5. Process nested procedures
        6. Process statements
        7. Exit scope (decrement depth and print symbol table)
        
        Args:
            node: The Prog node to analyze
            
        Returns:
            True if analysis succeeded, False if critical errors were found
        """
        self.logger.info("Analyzing Prog node")
        if node.name != "Prog":
            line, column = self.get_location_info(node)
            self.report_error(f"Expected 'Prog' node, got '{node.name}'", line, column)
            return False
            
        # Navigate through the procedure structure
        # Format: procedure idt Args is DeclarativePart Procedures begin SeqOfStatements end idt;
        
        # Get the procedure name (second child should be the identifier)
        if len(node.children) < 2 or node.children[1].name != "ID":  # Changed from "idt" to "ID"
            line, column = self.get_location_info(node.children[0] if node.children else node)
            self.report_error("Missing procedure identifier", line, column)
            return False
            
        proc_name_node = node.children[1]
        proc_name = proc_name_node.token.lexeme
        
        # Check if procedure name already exists at the current depth
        existing_entry = self.symbol_table.lookup(proc_name, self.current_depth)
        if existing_entry:
            line, column = self.get_location_info(proc_name_node)
            self.report_error(f"Duplicate declaration of procedure '{proc_name}'", line, column)
            return False
            
        # Insert procedure into symbol table at current depth
        self.logger.info(f"Inserting procedure '{proc_name}' into symbol table at depth {self.current_depth}")
        proc_entry = self.symbol_table.insert(proc_name, proc_name_node.token.token_type, self.current_depth)
        
        # Set initial procedure info (will update later)
        self.logger.debug(f"Initializing procedure info for '{proc_name}'")
        proc_entry.set_procedure_info(0, 0, None, [])
        proc_entry.entry_type = EntryType.PROCEDURE
        
        # Enter new scope for procedure body
        self.logger.debug(f"Entering new scope for procedure '{proc_name}'")
        self.current_depth += 1
        
        # Reset the offset for the new scope
        self.logger.debug(f"Resetting offset for new scope at depth {self.current_depth}")
        self.depth_offsets[self.current_depth] = 0
        self.current_offset = 0
        
        # Process procedure arguments (if any)
        self.logger.debug("Processing procedure arguments")
        args_node = self.find_child_by_name(node, "Args")
        if args_node:
            param_info = self.analyze_args(args_node)
            if param_info:
                param_count, param_list = param_info
                # Update procedure entry with formal parameter info;
                # Formal parameters are inserted at the new scope (depth + 1)
                self.logger.debug(f"Updating procedure entry for '{proc_name}' with parameter count {param_count}")
                proc_entry.param_count = param_count
                proc_entry.param_list = param_list
        
        
        # Process nested procedures
        procedures_node = self.find_child_by_name(node, "Procedures")
        if procedures_node:
            self.logger.debug("Processing nested procedures")
            self.analyze_procedures(procedures_node)
        
        # Process statements
        seq_of_statements_node = self.find_child_by_name(node, "SeqOfStatements")
        if seq_of_statements_node:
            self.logger.debug("Processing statements")
            self.analyze_seq_of_statements(seq_of_statements_node)
        
        # Update procedure entry with final local size
        self.logger.debug(f"Updating procedure entry for '{proc_name}' with local size {self.depth_offsets[self.current_depth]}")
        proc_entry.local_size = self.depth_offsets[self.current_depth]
        
        # Print symbol table for this scope
        self.logger.debug(f"Exiting procedure '{proc_name}' (depth {self.current_depth}):")
        print(f"\nExiting procedure '{proc_name}' (depth {self.current_depth}):")
        self.print_symbol_table(self.current_depth)
        
        # Delete entries at this depth as we exit the scope
        self.logger.debug(f"Deleting entries at depth {self.current_depth}")
        self.symbol_table.deleteDepth(self.current_depth)
        
        # Exit scope
        self.logger.debug(f"Exiting scope for procedure '{proc_name}'")
        self.current_depth -= 1
        
        # Restore parent scope's offset
        self.current_offset = self.depth_offsets[self.current_depth]
        
        self.logger.debug(f"Updating procedure entry for '{proc_name}' with local size {self.depth_offsets[self.current_depth]}")
        self.logger.debug(f"Exiting procedure '{proc_name}' (depth {self.current_depth}):")
        self.logger.debug(f"Deleting entries at depth {self.current_depth}")
        
        return True
    
    def analyze_declarative_part(self, node: ParseTreeNode) -> bool:
        """
        Analyze a DeclarativePart node in the parse tree.
        
        Grammar rule: DeclarativePart -> IdentifierList : TypeMark ; DeclarativePart | Îµ
        
        Actions:
        1. Process identifier list (get all variable/constant names)
        2. Process type mark (get type information for the variables/constants)
        3. Insert each identifier into the symbol table with the appropriate type info
        4. Recursively process the rest of the declarative part
        
        Args:
            node: The DeclarativePart node to analyze
            
        Returns:
            True if analysis succeeded, False if critical errors were found
        """
        if node.name != "DeclarativePart" or not node.children:
            # Empty declarative part (epsilon production)
            self.logger.debug("Empty declarative part")
            return True
            
        # The first child should be IdentifierList
        self.logger.debug("Processing IdentifierList")
        id_list_node = self.find_child_by_name(node, "IdentifierList")
        if not id_list_node:
            line, column = self.get_location_info(node.children[0] if node.children else node)
            self.report_error("Missing identifier list in declarative part", line, column)
            return False
            
        # Get list of identifiers
        self.logger.debug("Getting list of identifiers")
        identifiers = self.analyze_identifier_list(id_list_node)
        
        # Next should be a colon
        self.logger.debug("Processing colon")
        colon_index = self.find_child_index_by_token_type(node, "COLON")
        if colon_index == -1 or colon_index >= len(node.children):
            line, column = self.get_location_info(id_list_node)
            self.report_error("Missing colon in declarative part", line, column)
            return False
            
        # Next should be TypeMark
        self.logger.debug("Processing TypeMark")
        type_mark_node = self.find_child_by_name(node, "TypeMark") 
        if not type_mark_node:
            line, column = self.get_location_info(node.children[colon_index])
            self.report_error("Missing type mark in declarative part", line, column)
            return False
            
        # Process type mark to get variable type or constant info
        self.logger.debug("Processing type mark")
        type_info = self.analyze_type_mark(type_mark_node)
        if not type_info:
            return False
            
        # Determine if this is a variable or constant declaration
        self.logger.debug("Determining if this is a variable or constant declaration")
        is_constant, var_type, const_value = type_info
        
        # Insert each identifier into the symbol table
        for identifier in identifiers:
            # Check for duplicate declaration at current depth
            self.logger.debug(f"Checking for duplicate declaration of '{identifier.lexeme}'")
            existing_entry = self.symbol_table.lookup(identifier.lexeme, self.current_depth)
            if existing_entry:
                line, column = self.get_location_info(identifier)
                self.report_error(f"Duplicate declaration of '{identifier.lexeme}'", line, column)
                continue
                
            # Insert the identifier into the symbol table
            self.logger.debug(f"Inserting '{identifier.lexeme}' into the symbol table")
            entry = self.symbol_table.insert(identifier.lexeme, identifier.token_type, self.current_depth)
            
            if is_constant:
                self.logger.debug(f"Setting constant info for '{identifier.lexeme}'")
                # Set constant info
                entry.set_constant_info(var_type, const_value)
                entry.entry_type = EntryType.CONSTANT
            else:
                # Set variable info - determine size based on type
                self.logger.debug(f"Setting variable info for '{identifier.lexeme}'")
                size = self.type_sizes.get(var_type, 0)
                entry.set_variable_info(var_type, self.current_offset, size)
                entry.entry_type = EntryType.VARIABLE
                
                # Update offset for next variable
                self.current_offset += size
                self.depth_offsets[self.current_depth] = self.current_offset
        
        # Process the rest of the declarative part (if any)
        self.logger.debug("Processing remaining declarative part")
        semicolon_index = self.find_child_index_by_token_type(node, "SEMICOLON")
        if semicolon_index != -1 and semicolon_index < len(node.children) - 1:
            next_decl_part = node.children[semicolon_index + 1]
            self.logger.debug("Checking for next declarative part")
            self.logger.debug("Processing remaining declarative part")
            if next_decl_part.name == "DeclarativePart":
                self.analyze_declarative_part(next_decl_part)
        
        return True
    
    def analyze_identifier_list(self, node: ParseTreeNode) -> List[Token]:
        """
        Analyze an IdentifierList node in the parse tree.
        
        Grammar rule: IdentifierList -> idt | IdentifierList , idt
        
        Args:
            node: The IdentifierList node to analyze
            
        Returns:
            List of identifier tokens in the list
        """
        self.logger.debug("Analyzing identifier list")
        identifiers = []
        current_node = node
        
        while current_node:
            # Look for the identifier token in the current node
            self.logger.debug("Looking for identifier token")
            idt_node = None
            for child in current_node.children:
                if child.name == "ID":  # Changed from "idt" to "ID"
                    idt_node = child
                    identifiers.append(child.token)
                    break
            
            # Check if there's another IdentifierList (for comma-separated lists)
            next_list_node = self.find_child_by_name(current_node, "IdentifierList")
            if next_list_node:
                current_node = next_list_node
            else:
                break
                
        return identifiers
    
    def analyze_type_mark(self, node: ParseTreeNode) -> Optional[Tuple[bool, VarType, Any]]:
        """
        Analyze a TypeMark node in the parse tree.
        
        Grammar rule: TypeMark -> integert | realt | chart | float | const assignop Value
        
        Args:
            node: The TypeMark node to analyze
            
        Returns:
            Tuple of (is_constant, variable_type, constant_value) or None if error
        """
        self.logger.debug("Analyzing type mark")
        if not node.children:
            line, column = self.get_location_info(node)
            self.report_error("Empty type mark", line, column)
            return None
            
        # Get the first child which should be the type
        self.logger.debug("Getting first child")
        type_node = node.children[0]
        
        # Check if this is a constant declaration
        self.logger.debug("Checking if this is a constant declaration")
        if type_node.name == "const" or (type_node.token and type_node.token.token_type == "CONSTANT"):
            # Format: const assignop Value
            if len(node.children) < 3:
                line, column = self.get_location_info(type_node)
                self.report_error("Invalid constant declaration, missing value", line, column)
                return None
                
            # Check for assignment operator
            assign_node = node.children[1]
            if assign_node.name != "assignop" and (assign_node.token and assign_node.token.token_type != "ASSIGN"):
                line, column = self.get_location_info(type_node)
                self.report_error("Invalid constant declaration, missing assignment operator", line, column)
                return None
                
            # Get the value node
            value_node = self.find_child_by_name(node, "Value")
            if not value_node or not value_node.children:
                line, column = self.get_location_info(node.children[1])
                self.report_error("Invalid constant declaration, missing value", line, column)
                return None
                
            # Extract the value
            value_token = value_node.children[0].token
            
            # Determine the constant type based on the token type
            if value_token.token_type == "NUM" or value_token.token_type == "INTLIT":
                return (True, VarType.INT, int(value_token.lexeme))
            elif value_token.token_type == "REAL" or value_token.token_type == "FLOATLIT":
                return (True, VarType.FLOAT, float(value_token.lexeme))
            elif value_token.token_type == "CHRLIT":
                return (True, VarType.CHAR, value_token.lexeme.strip("'"))
            else:
                line, column = self.get_location_info(value_token)
                self.report_error(f"Invalid constant value type: {value_token.token_type}", line, column)
                return None
        else:
            # Variable type declaration
            if type_node.token and type_node.token.token_type in self.token_to_var_type:
                return (False, self.token_to_var_type[type_node.token.token_type], None)
            elif type_node.name.lower() == "integert":
                return (False, VarType.INT, None)
            elif type_node.name.lower() == "realt":
                return (False, VarType.FLOAT, None)
            elif type_node.name.lower() == "chart":
                return (False, VarType.CHAR, None)
            elif type_node.name.lower() == "float":
                return (False, VarType.FLOAT, None)
            else:
                line, column = self.get_location_info(type_node)
                self.report_error(f"Unknown type: {type_node.name}", line, column)
                return None
    
    def analyze_args(self, node: ParseTreeNode) -> Optional[Tuple[int, List[Parameter]]]:
        """
        Analyze an Args node in the parse tree.
        Returns (0, []) if the node does not contain valid arguments.
        """
        # If no children or first child does not have a token (i.e. is Îµ), then there are no arguments
        if not node.children or not (hasattr(node.children[0], "token") and node.children[0].token):
            return (0, [])
        if node.children[0].token.token_type != "LPAREN":
            return (0, [])
        # Otherwise, look for ArgList and process
        arg_list_node = self.find_child_by_name(node, "ArgList")
        if not arg_list_node:
            return (0, [])
        return self.analyze_arg_list(arg_list_node)
    
    def analyze_arg_list(self, node: ParseTreeNode) -> Tuple[int, List[Parameter]]:
        """
        Analyze an ArgList node in the parse tree.
        
        Grammar rule: ArgList -> Mode IdentifierList : TypeMark MoreArgs
        
        Args:
            node: The ArgList node to analyze
            
        Returns:
            Tuple of (parameter_count, parameter_list)
        """
        params = []
        current_node = node
        
        while current_node:
            # Process Mode
            mode_node = self.find_child_by_name(current_node, "Mode")
            param_mode = self.analyze_mode(mode_node) if mode_node else ParameterMode.IN  # Default to IN
            
            # Process IdentifierList
            id_list_node = self.find_child_by_name(current_node, "IdentifierList")
            if not id_list_node:
                line, column = self.get_location_info(current_node.children[0] if current_node.children else current_node)
                self.report_error("Missing identifier list in argument list", line, column)
                break
                
            identifiers = self.analyze_identifier_list(id_list_node)
            
            # Verify colon presence
            colon_index = self.find_child_index_by_token_type(current_node, "COLON")
            if colon_index == -1:
                line, column = self.get_location_info(id_list_node.children[-1] if id_list_node.children else id_list_node)
                self.report_error("Missing colon in parameter declaration", line, column)
                break
                
            # Process TypeMark
            type_mark_node = self.find_child_by_name(current_node, "TypeMark")
            if not type_mark_node:
                line, column = self.get_location_info(current_node.children[colon_index])
                self.report_error("Missing type mark in parameter declaration", line, column)
                break
                
            # Get type information
            type_info = self.analyze_type_mark(type_mark_node)
            if not type_info:
                break
                
            # We only support variable parameters, not constant parameters
            is_constant, var_type, _ = type_info
            if is_constant:
                line, column = self.get_location_info(type_mark_node.children[0])
                self.report_error("Constants cannot be used as parameters", line, column)
                break
                
            # Create parameter objects for each identifier
            for identifier in identifiers:
                # First check if this parameter name already exists at the current depth
                existing_entry = self.symbol_table.lookup(identifier.lexeme, self.current_depth)
                if existing_entry:
                    line, column = self.get_location_info(identifier)
                    self.report_error(f"Duplicate declaration of parameter '{identifier.lexeme}'", line, column)
                    continue
                    
                # Create a parameter object
                param = Parameter(var_type, param_mode)
                params.append(param)
                
                # Insert parameter into symbol table
                entry = self.symbol_table.insert(identifier.lexeme, identifier.token_type, self.current_depth)
                
                # Set as variable with offset
                size = self.type_sizes.get(var_type, 0)
                entry.set_variable_info(var_type, self.current_offset, size)
                entry.entry_type = EntryType.VARIABLE
                
                # Update offset
                self.current_offset += size
                self.depth_offsets[self.current_depth] = self.current_offset
            
            # Check for more arguments
            more_args_node = self.find_child_by_name(current_node, "MoreArgs")
            if more_args_node and more_args_node.children:
                # Check if it has a semicolon, which indicates more arguments
                if more_args_node.children[0].token.token_type == "SEMICOLON":
                    # Look for the next ArgList
                    next_arg_list = self.find_child_by_name(more_args_node, "ArgList")
                    if next_arg_list:
                        current_node = next_arg_list
                        continue
            
            # No more arguments
            break
        
        return (len(params), params)
    
    def analyze_mode(self, node: ParseTreeNode) -> ParameterMode:
        """
        Analyze a Mode node in the parse tree.
        
        Grammar rule: Mode -> in | out | inout | Îµ
        
        Args:
            node: The Mode node to analyze
            
        Returns:
            Parameter mode (IN, OUT, or INOUT)
        """
        if not node or not node.children:
            return ParameterMode.IN  # Default if not specified
            
        mode_token = node.children[0].token
        if mode_token.token_type == "IN":
            return ParameterMode.IN
        elif mode_token.token_type == "OUT":
            return ParameterMode.OUT
        elif mode_token.token_type == "INOUT":
            return ParameterMode.INOUT
        else:
            line, column = self.get_location_info(mode_token)
            self.report_error(f"Invalid parameter mode: {mode_token.lexeme}", line, column)
            return ParameterMode.IN  # Default to IN on error
    
    def analyze_procedures(self, node: ParseTreeNode) -> bool:
        """
        Analyze a Procedures node in the parse tree.
        
        Grammar rule: Procedures -> Prog Procedures | Îµ
        
        Args:
            node: The Procedures node to analyze
            
        Returns:
            True if analysis succeeded, False if critical errors were found
        """
        if not node or not node.children:
            # No nested procedures (epsilon production)
            return True
            
        # Process the first Prog node (nested procedure)
        prog_node = self.find_child_by_name(node, "Prog")
        if prog_node:
            if not self.analyze_prog(prog_node):
                return False
        
        # Process the rest of the procedures (if any)
        next_procedures = self.find_child_by_name(node, "Procedures")
        if next_procedures and next_procedures.children:
            return self.analyze_procedures(next_procedures)
            
        return True
    
    def analyze_seq_of_statements(self, node: ParseTreeNode) -> bool:
        """
        Analyze a SeqOfStatements node in the parse tree.
        
        Grammar rule: SeqOfStatements -> Statement ; SeqOfStatements | Îµ
        
        Args:
            node: The SeqOfStatements node to analyze
            
        Returns:
            True if analysis succeeded, False if critical errors were found
        """
        if not node or not node.children:
            # Empty sequence of statements (epsilon production)
            return True
            
        # Process the first statement
        statement_node = self.find_child_by_name(node, "Statement")
        if statement_node:
            self.analyze_statement(statement_node)
        
        # Process the rest of the statements (if any)
        semicolon_index = self.find_child_index_by_token_type(node, "SEMICOLON")
        if semicolon_index != -1 and semicolon_index < len(node.children) - 1:
            next_seq_of_statements = node.children[semicolon_index + 1]
            if next_seq_of_statements.name == "SeqOfStatements":
                return self.analyze_seq_of_statements(next_seq_of_statements)
            
        return True
    
    def analyze_statement(self, node: ParseTreeNode) -> bool:
        """
        Analyze a Statement node in the parse tree.
        
        Grammar rule: Statement -> Assignment | ProcedureCall | IfStatement | LoopStatement
        
        Args:
            node: The Statement node to analyze
            
        Returns:
            True if analysis succeeded, False if critical errors were found
        """
        # Placeholder for statement analysis logic
        return True
    
    def print_symbol_table(self, depth: Optional[int] = None) -> None:
        """
        Print the contents of the symbol table at the specified depth.
        If depth is None, print the entire symbol table.
        
        Args:
            depth: The lexical scope depth to print, or None for all depths
        """
        if depth is not None:
            entries = self.symbol_table.writeTable(depth)
            self._print_entries_table(entries, depth)
        else:
            # Find all depths in the symbol table
            depths = set()
            for i in range(self.symbol_table.table_size):
                entry = self.symbol_table.table[i]
                while entry is not None:
                    depths.add(entry.depth)
                    entry = entry.next
            
            # Print entries for each depth
            for d in sorted(depths):
                entries = self.symbol_table.writeTable(d)
                self._print_entries_table(entries, d)
    
    def _print_entries_table(self, entries: Dict[str, TableEntry], depth: int) -> None:
        """
        Print a nicely formatted table of symbol table entries for a specific depth.
        
        Args:
            entries: Dictionary mapping lexemes to their table entries
            depth: The depth these entries are from
        """
        if not entries:
            print(f"\nNo entries at depth {depth}")
            return
            
        print(f"\nEntries at depth {depth}:")
        
        # Create a pretty table
        table = PrettyTable()
        table.field_names = ["Lexeme", "Type", "Data Type", "Size", "Offset/Value", "Other Info"]
        
        for lexeme, entry in sorted(entries.items()):
            entry_type = entry.entry_type.name if entry.entry_type else "UNKNOWN"
            
            if entry.entry_type == EntryType.VARIABLE:
                data_type = entry.var_type.name if entry.var_type else "UNKNOWN"
                size = str(entry.size) if entry.size is not None else "-"
                offset = str(entry.offset) if entry.offset is not None else "-"
                other = "-"
            elif entry.entry_type == EntryType.CONSTANT:
                data_type = entry.const_type.name if entry.const_type else "UNKNOWN"
                size = "-"
                offset = str(entry.const_value) if entry.const_value is not None else "-"
                other = "-"
            elif entry.entry_type == EntryType.PROCEDURE:
                data_type = entry.return_type.name if entry.return_type else "VOID"
                size = str(entry.local_size) if entry.local_size is not None else "-"
                offset = "-"
                params = [str(p) for p in entry.param_list] if entry.param_list else []
                other = f"Params: {', '.join(params)}" if params else "-"
            else:
                data_type = "-"
                size = "-"
                offset = "-"
                other = "-"
                
            table.add_row([lexeme, entry_type, data_type, size, offset, other])
        
        print(table)
    
    def print_errors(self) -> None:
        """
        Print all semantic errors in a formatted table.
        """
        if not self.errors:
            print("\nNo semantic errors detected.")
            return
            
        print("\nSemantic Errors:")
        
        table = PrettyTable()
        table.field_names = ["Line", "Column", "Error Message"]
        
        for error in self.errors:
            line = error.get("line", "-")
            column = error.get("column", "-")
            message = error.get("message", "Unknown error")
            table.add_row([line, column, message])
            
        print(table)
    
    def report_error(self, message: str, line: int = 0, column: int = 0) -> None:
        """
        Report a semantic error.
        
        Args:
            message: The error message
            line: The line number where the error occurred
            column: The column number where the error occurred
        """
        error = {
            "message": message,
            "line": line,
            "column": column
        }
        
        self.errors.append(error)
        self.logger.error(f"Semantic error at line {line}, column {column}: {message}")
        
        if self.stop_on_error:
            print(f"Semantic error at line {line}, column {column}: {message}")
            response = input("Continue analysis? (y/n): ")
            if response.lower() != 'y':
                raise Exception(f"Analysis stopped due to error: {message}")
    
    def get_location_info(self, node_or_token) -> tuple:
        """
        Extract line and column information from a node or token.
        
        Args:
            node_or_token: Either a ParseTreeNode or Token object
        
        Returns:
            Tuple of (line_number, column_number)
        """
        if hasattr(node_or_token, "token") and node_or_token.token:
            # It's a node with a token
            return (node_or_token.token.line_number, node_or_token.token.column_number)
        elif hasattr(node_or_token, "line_number") and hasattr(node_or_token, "column_number"):
            # It's a token
            return (node_or_token.line_number, node_or_token.column_number)
        else:
            # No location info available
            return (0, 0)
    
    def find_child_by_name(self, node: ParseTreeNode, name: str) -> Optional[ParseTreeNode]:
        """
        Helper method to find a child node by name.
        
        Args:
            node: The parent node
            name: The name of the child node to find
            
        Returns:
            The child node if found, None otherwise
        """
        if not node or not node.children:
            return None
            
        for child in node.children:
            if child.name == name:
                return child
                
        return None
    
    def find_child_index_by_token_type(self, node: ParseTreeNode, token_type: str) -> int:
        """
        Helper method to find the index of a child node by token type.
        
        Args:
            node: The parent node
            token_type: The token type to search for
            
        Returns:
            The index of the child if found, -1 otherwise
        """
        if not node or not node.children:
            return -1
            
        for i, child in enumerate(node.children):
            if child.token and child.token.token_type == token_type:
                return i
                
        return -1


# Example usage
if __name__ == "__main__":
    # This would be used for testing the module independently
    print("SemanticAnalyzer module - integrate with JohnA5.py driver program")
